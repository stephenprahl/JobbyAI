# Server Configuration
PORT=3001
NODE_ENV=development

# CORS Configuration
CORS_ORIGIN=http://localhost:3000

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000  # 15 minutes
RATE_LIMIT_MAX=100

# Logging
LOG_LEVEL=debug

# Ollama Configuration (for AI analysis)
# Make sure Ollama is running locally at the specified URL
OLLAMA_API_URL=http://localhost:11434
# Default model to use (e.g., llama3, mistral, etc.)
OLLAMA_MODEL=llama3
# Controls randomness in the AI's responses (0.0 to 1.0)
OLLAMA_TEMPERATURE=0.7

# JWT Configuration (for future authentication)
JWT_SECRET=your_jwt_secret_here
JWT_EXPIRES_IN=7d

# Database Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=resume_plan_ai
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost:5432/${POSTGRES_DB}

# Redis (for rate limiting and caching)
# REDIS_URL=redis://localhost:6379

# Sentry (for error tracking)
# SENTRY_DSN=your_sentry_dsn_here
